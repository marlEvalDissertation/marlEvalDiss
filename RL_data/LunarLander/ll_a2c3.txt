========== LunarLander-v2 ==========
Seed: 1567692195
Loading hyperparameters from: /content/rl-baselines3-zoo/hyperparams/a2c.yml
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('ent_coef', 1e-05),
             ('gamma', 0.995),
             ('learning_rate', 'lin_0.00083'),
             ('n_envs', 8),
             ('n_steps', 5),
             ('n_timesteps', 200000.0),
             ('policy', 'MlpPolicy')])
Log path: logs/a2c/LunarLander-v2_4
Eval num_timesteps=10000, episode_reward=-1083.41 +/- 174.69
Episode length: 378.40 +/- 24.27
New best mean reward!
Eval num_timesteps=20000, episode_reward=-2820.94 +/- 541.04
Episode length: 589.30 +/- 55.21
Eval num_timesteps=30000, episode_reward=-682.64 +/- 85.26
Episode length: 782.20 +/- 116.17
New best mean reward!
Eval num_timesteps=40000, episode_reward=-333.99 +/- 192.79
Episode length: 967.10 +/- 98.70
New best mean reward!
Eval num_timesteps=50000, episode_reward=-628.49 +/- 385.21
Episode length: 890.90 +/- 218.45
Eval num_timesteps=60000, episode_reward=-260.15 +/- 244.12
Episode length: 903.80 +/- 150.06
New best mean reward!
Eval num_timesteps=70000, episode_reward=-377.04 +/- 212.29
Episode length: 923.20 +/- 154.35
Eval num_timesteps=80000, episode_reward=-115.35 +/- 236.20
Episode length: 868.10 +/- 218.10
New best mean reward!
Eval num_timesteps=90000, episode_reward=-296.58 +/- 271.41
Episode length: 827.40 +/- 273.58
Eval num_timesteps=100000, episode_reward=-30.34 +/- 234.44
Episode length: 689.80 +/- 241.58
New best mean reward!
Saving to logs/a2c/LunarLander-v2_4
