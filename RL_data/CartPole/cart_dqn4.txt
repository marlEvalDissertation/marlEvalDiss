========== CartPole-v1 ==========
Seed: 3302075248
Loading hyperparameters from: /content/rl-baselines3-zoo/hyperparams/dqn.yml
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('batch_size', 64),
             ('buffer_size', 100000),
             ('exploration_final_eps', 0.04),
             ('exploration_fraction', 0.16),
             ('gamma', 0.99),
             ('gradient_steps', 128),
             ('learning_rate', 0.0023),
             ('learning_starts', 1000),
             ('n_timesteps', 50000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs', 'dict(net_arch=[256, 256])'),
             ('target_update_interval', 10),
             ('train_freq', 256)])
Log path: logs/dqn/CartPole-v1_4
Eval num_timesteps=10000, episode_reward=78.40 +/- 3.93
Episode length: 78.40 +/- 3.93
New best mean reward!
Eval num_timesteps=20000, episode_reward=92.10 +/- 1.70
Episode length: 92.10 +/- 1.70
New best mean reward!
Eval num_timesteps=30000, episode_reward=101.00 +/- 1.34
Episode length: 101.00 +/- 1.34
New best mean reward!
Eval num_timesteps=40000, episode_reward=500.00 +/- 0.00
Episode length: 500.00 +/- 0.00
New best mean reward!
Eval num_timesteps=50000, episode_reward=500.00 +/- 0.00
Episode length: 500.00 +/- 0.00
Eval num_timesteps=60000, episode_reward=159.70 +/- 5.97
Episode length: 159.70 +/- 5.97
Eval num_timesteps=70000, episode_reward=96.80 +/- 8.58
Episode length: 96.80 +/- 8.58
Eval num_timesteps=80000, episode_reward=95.90 +/- 1.70
Episode length: 95.90 +/- 1.70
Eval num_timesteps=90000, episode_reward=35.30 +/- 31.44
Episode length: 35.30 +/- 31.44
Eval num_timesteps=100000, episode_reward=122.40 +/- 3.47
Episode length: 122.40 +/- 3.47
Saving to logs/dqn/CartPole-v1_4
